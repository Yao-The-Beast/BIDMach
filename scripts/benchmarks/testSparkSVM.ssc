import org.apache.spark.SparkContext
import org.apache.spark.mllib.classification.SVMWithSGD
import org.apache.spark.mllib.evaluation.BinaryClassificationMetrics
import org.apache.spark.mllib.regression.LabeledPoint
import org.apache.spark.mllib.linalg.Vectors
import org.apache.spark.mllib.util.MLUtils
import scala.compat.Platform._ 

val t0=currentTime
// Load training data in LIBSVM format.
val data = MLUtils.loadLibSVMFile(sc, "/big/RCV1/v2/train6.libsvm")
val t1=currentTime

// Split data into training (90%) and test (10%).
val splits = data.randomSplit(Array(0.9, 0.1), seed = 11L)
val training = splits(0).cache()
val test = splits(1)
val t2=currentTime

// Run training algorithm to build the model
val numIterations = 100
val model = SVMWithSGD.train(training, numIterations)

val t3=currentTime

// Clear the default threshold.
model.clearThreshold()

// Compute raw scores on the test set. 
val scoreAndLabels = test.map { point =>
  val score = model.predict(point.features)
  (score, point.label)
}

val t4=currentTime

// Get evaluation metrics.
val metrics = new BinaryClassificationMetrics(scoreAndLabels)
val auROC = metrics.areaUnderROC()
println("Area under ROC = " + auROC)

println("load time %f, split %f, train %f, predict %f" format ((t1-t0)/1000f,
(t2-t1)/1000f, (t3-t2)/1000f, (t4-t3)/1000f))
